create_plan:
  description: |
    You are given a causal question or a dataset with a user query. Begin by identifying the treatment(s), outcome(s),
    and any relevant confounders or domain assumptions. Use this information to formulate a causal analysis plan consisting
    of structured subgoals, each targeting a phase in the pipeline such as:
    - Background literature search and constraint identification
    - Data preprocessing and diagnostics
    - Causal graph discovery (e.g., PC, NOTEARS, LiNGAM)
    - Validation using cross-evidence or simulation
    - Causal inference (e.g., effect estimation)
    - Result interpretation and reporting

    For each subgoal, specify the objective and expected output only. Do not assign agents — this will be handled in later steps.
    Write the resulting subgoal list to 'SubGoals.json'.

    {self.__tip_section()}

    User query: {causal_query}
    Dataset: {dataset_name}
  expected_output: |
    A file named 'SubGoals.json' containing a list of 4-6 subgoals tailored to the causal question. Each subgoal must include:

    - description: a clear, concise goal (e.g., \"Run causal discovery on the cleaned dataset using NOTEARS\")
    - expected_output: the expected deliverable for the subgoal (e.g., \"a DAG with estimated edge weights and adjacency matrix\")
    - status: always initialized as 'pending'
    - score: null
    - feedback: null

    Example structure:
    [
      {
        "id": 1,
        "description": "Perform literature review on potential confounders between variable X and Y",
        "expected_output": "A list of at least 3 relevant papers and a summary of domain constraints",
        "status": "pending",
        "score": null,
        "feedback": null
      },
      ...
    ]
  agent: scientist_agent

start_subgoal:
  description: |
    Read 'SubGoals.json' and identify the first subgoal where status != 'completed' and (score == null or score < {threshold}).
    Decompose this subgoal into 2-4 smaller subsubgoals that can be executed independently, each assigned to a specialized agent.

    For example:
    - If the subgoal involves causal discovery, assign:
      • Data diagnostics to CodingAgent
      • Run NOTEARS algorithm to DiscoveryAgent
      • Literature cross-check to VerificationAgent
    - If the subgoal involves validation, assign:
      • Literature search to SearchAgent
      • Counterfactual simulation to VerificationAgent

    Save the resulting subsubgoals to a file named 'SubSubGoals.json'. Each subsubgoal must include:
    - id: unique subsubgoal ID
    - parent_id: corresponding subgoal ID
    - description: a concise task definition
    - assigned_agent: name of the agent responsible
    - status: initialized as 'pending'
    - tool_hints: optional suggestions (e.g., algorithm or dataset to use)

    Also, update the corresponding subgoal in 'SubGoals.json' to status='in_progress'.

    {self.__tip_section()}

    Threshold: {threshold}
  expected_output: |
    'SubSubGoals.json' containing 2-4 well-defined subsubgoals, each with:
    - id
    - parent_id
    - description
    - assigned_agent
    - status='pending'
    - Optional: tool_hints

    'SubGoals.json' is updated with the selected subgoal marked as status='in_progress'.
  agent: assistant_agent

collect_subgoal_results:
  description: |
    Read 'SubSubGoals.json' and identify all subsubgoals with status='completed'. Group them by their parent_id.

    For each group:
    1. Synthesize a comprehensive summary of the outputs based on subgoal type:
        - *Discovery*: include DAG or CPDAG structure, algorithm used, edge confidence, and any assumptions or limitations
        - *Validation*: include literature support, consistency checks, and simulation results
        - *Inference*: include effect estimates, standard errors, confidence intervals, and assumptions

    2. Write the synthesized summary into the parent subgoal (in 'SubGoals.json') under the field combined_result.

    3. Mark the parent subgoal's status as 'for_review'.

    4. Update all related subsubgoals in 'SubSubGoals.json' to status='completed'.

    Format the summary according to the requested style:
    - 'structured': use numbered bullet points and section headers
    - 'narrative': use paragraph-style explanation with contextual transitions

    {self.__tip_section()}

    Summary style: {summary_style}
  expected_output: |
    'SubGoals.json' is updated with:
    - combined_result: a synthesized, human-readable summary for each updated subgoal
    - status='for_review' for each parent subgoal

    'SubSubGoals.json' is updated with:
    - All related subsubgoals marked as status='completed'
  agent: assistant_agent

evaluate_subgoal:
  description: |
    Read 'SubGoals.json' and identify all subgoals with status='for_review'. For each, review the combined_result field and evaluate its quality using the following criteria:

    Evaluation by subgoal type:
    - *Discovery*: assess graph clarity, validity of methods, and confidence in inferred relationships
    - *Validation*: examine consistency across literature, simulations, and assumptions
    - *Inference*: verify interpretability of causal effect estimates and robustness of assumptions

    For each subgoal:
    1. Assign a score between 0.0 and 1.0.
    2. Provide concise but specific feedback highlighting strengths or deficiencies.
    3. Compare the score to the threshold:
        - If score |= {threshold}, mark the subgoal as 'completed'
        - If score < {threshold}, mark it 'pending' and suggest refinements

    Save all updates back to 'SubGoals.json'.

    {self.__tip_section()}

    Evaluation threshold: {threshold}
  expected_output: |
    'SubGoals.json' is updated with:
    - score: float between 0.0 and 1.0
    - feedback: evaluator's written response
    - status: set to 'completed' or 'pending' based on whether the score meets the threshold
    for each subgoal with status='for_review'.
  agent: scientist_agent